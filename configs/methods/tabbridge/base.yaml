trainer:
  ckpt_track_metric: loss
  metrics_on_train: True
  ema_metrics_on_train: True
  total_iters: 10_000_000 # may be it is too much...
  use_trainval: False
  patience: -1
  ema:
    beta: 0.9999
    update_after_step: 25000
    update_every: 10

data_conf:
  train_resamples: 25
  batch_size: 256
  train_random_end: time
  train_transforms:
    '1':
      TimeToDiff:
        disable: true # Base processing must be minimal
    "3":
      CutTargetSequence:
        target_len: ${data_conf.generation_len}

# MODEL
model:
  name: LatentDiffusionGenerator
  autoencoder: 
    name: VAE
    params:
      use_time: True
    pretrain: False
    frozen: True

  latent_encoder:
    name: ConditionalBridgeEncoder
    params:
      generation_len: ${data_conf.generation_len}
      history_len: ${data_conf.generation_len} # может быть это, или 0
      base_factor: 512 # unetS: 64, unetM: 128, unetL: 256, unetXL: 512
      dim_t : 1024
      num_classes: 1
      noise_schedule: ve #ve, vp, i2sb
      gen_sampler: dbim # heun, dbim, dbim_high_order
      sampling_nfe: 50


optimizer:
  name: AdamW
  params:
    lr: 1.e-4
    betas:
     - 0.9
     - 0.999
    eps: 1e-8
    weight_decay: 1.e-2

schedulers:
  "step":
    StepLR:
      step_size: 20
      gamma: 0.2

loss:
  name: DummyLoss