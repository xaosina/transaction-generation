config_factory: [start, datasets/age/age, methods/tabbridge/base, metrics/with_detection/age]

trainer:
  ema:
    beta: 0.9999
    update_after_step: 40000
    update_every: 10

model:
  autoencoder:
    params:
      d_token: 8
      num_layers: 10
      n_head: 4
      factor: 28
    checkpoint: /workspace/transactionsv2/transaction-generation/log/generation/age/ready/vae/seed_0/ckpt/epoch__0351_-_loss__-0.002042.ckpt
  
  latent_encoder:
    params:
      base_factor: 512 # unetXL
  
  params:
    repeat_matching: False
    
    history_encoder:
      name: GRU


optimizer:
  name: AdamW
  params:
    lr: 1.e-3
    betas:
     - 0.9
     - 0.999
    eps: 1e-8
    weight_decay: 1.e-2