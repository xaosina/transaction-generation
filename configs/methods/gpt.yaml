model:
  name: AutoregressiveGenerator
  autoencoder:
    name: BaselineAE
    params:
      cat_emb_dim: 768
      num_emb_dim: 64
      num_norm: True
    pretrain: False
    frozen: False
    checkpoint:
    batch_transforms:
      '0':
        TimeToFeatures:
          process_type: "cat"
      'set_features':
        Identity
        # HideFeaturesFromTrain:
        #   cat_features: 
        #   num_features: 
        #     - amount


  latent_encoder:
    name: GPT
    params:
      max_len: ${data_conf.max_seq_len}
      n_layer: 6
      n_head: 6
      n_embd: 768
      dropout: 0.2
      bias: True

data_conf.max_seq_len: 512


optimizer:
  name: Adam
  params:
    lr: 1.5e-3
    weight_decay: 1.e-9

schedulers:
  "step":
    StepLR:
      step_size: 30
  # "beta":
  #   BetaScheduler:
  #     init_beta: 0.01
  #     factor: 0.7
  #     patience: 4
  #     min_beta: 0.00001
  #     verbose: True

loss:
  name: baseline
  params:
    mse_weight: 0.07

optuna:
  params:
    n_trials: 70
    n_startup_trials: 3
    request_list: 
      - 'optimizer.params.weight_decay': 1.5429769361370426e-13
        'optimizer.params.lr': 0.00016912601015410544
        'model.latent_encoder.params.hidden_size': 164
        'model.latent_encoder.params.num_layers': 3
        'model.latent_encoder.params.dropout': 0.1831228989111418
        "model.autoencoder.batch_transforms.'0'.TimeToFeatures.process_type": cat
        'model.autoencoder.num_norm': false
        'model.autoencoder.cat_emb_dim': 41
        'model.autoencoder.num_emb_dim': 60
        'loss.params.mse_weight': 0.5
        'data_conf.train_transforms.1.TimeToDiff.disable': True
    target_metric: ${trainer.ckpt_track_metric}
  suggestions:
    - ["optimizer.params.weight_decay", ["suggest_float", {low: 1.e-15, high: 1.e-3, log: True}]]
    - ["optimizer.params.lr", ["suggest_float", {low: 1.e-5, high: 0.1, log: True}]]

    - ["model.latent_encoder.params.n_layer", [suggest_int, {low: 1, high: 12, log: False}]]
    - ["model.latent_encoder.params.n_head", [suggest_categorical, {choices: [1, 2, 4, 8, 16]}]]
    - ["model.latent_encoder.params.n_embd", [suggest_int, {low: 16, high: 960, log: False, step: 16}]]
    - ["model.latent_encoder.params.dropout", [suggest_float, {low: 0, high: 0.6, log: False}]]
    - ["model.latent_encoder.params.bias", [suggest_categorical, {choices: [True, False]}]]


    - ["model.autoencoder.batch_transforms.0.TimeToFeatures.process_type", ["suggest_categorical", {choices: ["diff", "cat", "none"]}]]
    - 
      - ["data_conf.train_transforms.1.TimeToDiff.disable", "data_conf.val_transforms.1.TimeToDiff.disable"]
      - ["suggest_categorical", {choices: [True, False]}]
    - ["model.autoencoder.num_norm", ["suggest_categorical", {choices: [True, False]}]]
    - ["model.autoencoder.cat_emb_dim", ["suggest_int", {low: 1, high: 128, log: False}]]
    - ["model.autoencoder.num_emb_dim", ["suggest_int", {low: 1, high: 128, log: False}]]

    - ["loss.params.mse_weight", ["suggest_float", {low: 0, high: 1, log: False}]]
