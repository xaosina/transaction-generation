trainer:
  ckpt_track_metric: loss
  metrics_on_train: True
  total_iters: 10_000_000 # may be it is too much...
  ema:
    beta: 0.9999
    update_after_step: 15000
    update_every: 10

evaluator:
  devices: ["cuda:0", "cuda:0", "cuda:0"]
  
data_conf:
  train_resamples: 50
  batch_size: 256
  train_random_end: time
  train_transforms:
    '1':
      TimeToDiff:
        disable: true #IMPORTANT: make sure it is consistent with VAE!
    "3":
      CutTargetSequence:
        target_len: ${data_conf.generation_len}


# MODEL
model:
  name: AsynDiffGenerator
  autoencoder: 
    name: VAE
    params:
      num_layers: 10
      d_token: 8
      n_head: 4
      factor: 28
      use_time: True
    pretrain: False
    frozen: True
    checkpoint: 


  latent_encoder:
    name: AsynDiffEncoder 
    params:
      num_rows:  64
      latent_size: 32 ## d_token * num_features in training
      hidden_size: 1152 ## must be the times of laten_size
      depth: 7
      num_heads: 16
      mlp_ratio: 4
      learn_sigma: False
      loss_type: l2-squared # l2,l2-squared and huber
      mask: False
      schedule: Sync
      int_ode: rk4
      generation_len: 32
      history_len: 32
      data_init: False


optimizer:
  name: AdamW
  params:
    lr: 1.e-4
    betas:
     - 0.9
     - 0.999
    eps: 1e-8
    weight_decay: 1.e-2
    wd_exclude_bias_ln: True

schedulers:
#   "cos":
#     CosineWithWarmUp:
#       warmup: 5
#       total_steps: 100
  "step":
    StepLR:
      step_size: 10 # no scheduler
      gamma: 0.2

loss:
  name: DummyLoss

