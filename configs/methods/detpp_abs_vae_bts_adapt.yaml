# MODEL
# Hardcoded 1 layer
# Always "_presence": 4
# Increase max wd
# Increase max k_factor
# Since we have bad correlation with loss and metric (loss increases with k_factor):
#     Replace target metric to GenOTD

model:
  name: DeTPP_abs_adapt
  autoencoder:
    name: VAE
    params:
      use_time: true
      d_token: 8
      num_layers: 10
      n_head: 4
      factor: 28
      cat_emb_dim: 88
      num_emb_dim: 109
    pretrain: False
    frozen: True
    checkpoint: /trinity/home/j.chen/2.SeqDiff/test/transaction-generation/ckpt/vae_age/old_vae_age.ckpt
    batch_transforms:
    - RescaleTime:
        loc: 0
        scale: 730

  latent_encoder:
    name: GRU
    params:
      hidden_size: 512
      num_layers: 1
  params:
    k_factor: 1

optimizer:
  name: Adam
  params:
    lr: 1.5e-3
    weight_decay: 1.e-9

schedulers:
  "step":
    StepLR:
      step_size: 30

loss:
  name: DeTPPLoss_abs
  params: 
    loss_subset: 0.1
    matching_weights: {"_presence": 4}


data_conf:
  batch_size: 32
  train_transforms:
    "0":
      RescaleTime:
        loc: 0.0
        scale: 1.0
    "1":
      TimeToDiff:
        disable: True
  val_transforms:
    "1":
      TimeToDiff:
        disable: True

trainer:
  ckpt_track_metric: 'loss'
  metrics_on_train: True

optuna:
  params:
    n_trials: 100
    n_startup_trials: 10
    request_list:
    - "optimizer.params.weight_decay": 2.005817028224756e-07
      "optimizer.params.lr": 0.0008546773813094806
      "model.latent_encoder.params.hidden_size": 452
      "model.params.k_factor": 1.4356463521292926
      "model.autoencoder.params.num_norm": true
      "model.autoencoder.params.cat_emb_dim": 33
      "model.autoencoder.params.num_emb_dim": 1
    target_metric: "GenOTD"
  suggestions:
    - ["optimizer.params.weight_decay", ["suggest_float", {low: 1.e-15, high: 1, log: True}]]
    - ["optimizer.params.lr", ["suggest_float", {low: 1.e-5, high: 0.1, log: True}]]

    - ["model.latent_encoder.params.hidden_size", ["suggest_int", {low: 10, high: 1200, log: True}]]
    # - ["model.latent_encoder.params.num_layers", ["suggest_int", {low: 1, high: 10, log: False}]]
    # - ["model.latent_encoder.params.dropout", ["suggest_float", {low: 1.e-10, high: 0.3, log: True}]]
    - ["model.params.k_factor", ["suggest_float", {low: 1, high: 10, log: False}]]

    # - ["loss.params.matching_weights._presence", ["suggest_float", {low: 0, high: 10, log: False}]]

    - ["model.autoencoder.params.num_norm", ["suggest_categorical", {choices: [True, False]}]]
    - ["model.autoencoder.params.cat_emb_dim", ["suggest_int", {low: 1, high: 128, log: False}]]
    - ["model.autoencoder.params.num_emb_dim", ["suggest_int", {low: 1, high: 128, log: False}]]
