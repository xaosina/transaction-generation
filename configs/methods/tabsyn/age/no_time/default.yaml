config_factory: [start, datasets/age/age, methods/tabsyn/base, metrics/with_detection/age]

trainer:
  ema:
    beta: 0.9999
    update_after_step: 10000
    update_every: 10

model:
  autoencoder:
    params:
      d_token: 8
      num_layers: 10
      n_head: 4
      factor: 28
      use_time: False
    pretrain: False
    frozen: True
    checkpoint: /home/transaction-generation/log/generation/ready/age/vae_no_time.ckpt
    batch_transforms:

  latent_encoder:
    params:
      base_factor: 512 # unetXL

data_conf:
  train_resamples: 5
  batch_size: 128

optimizer:
  name: AdamW
  params:
    lr: 1.e-3
    weight_decay: 1.e-2

schedulers:
  "step":
    StepLR:
      step_size: 20
      gamma: 0.2