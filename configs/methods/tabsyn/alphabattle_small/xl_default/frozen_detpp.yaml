config_factory: [start, datasets/alphabattle_small/alphabattle_small, methods/tabsyn/base, metrics/with_detection/alphabattle_small]

model:
  autoencoder:
    params:
      d_token: 64
      num_layers: 8
      n_head: 4
      factor: 10
    checkpoint: /home/transaction-generation/log/generation/ready/alphabattle_small/old_vae.ckpt
  latent_encoder:
    params:
      base_factor: 512 # unetXL
  params:
    history_encoder:
      checkpoint: /home/transaction-generation/log/generation/ready/alphabattle_small/detpp.ckpt
      name: DeTPP
      latent_encoder:
        name: GRU
        params:
          hidden_size: 198
          num_layers: 1
          dropout: 6.156057736007828e-06
      autoencoder:
        name: BaselineAE
        params:
          cat_emb_dim: 26
          num_emb_dim: 87
          num_norm: false
          use_time: true
        pretrain: false
        frozen: True
        checkpoint: null
        batch_transforms: null
      pooler: last
      params:
        k_factor: 1.9880601780691256

data_conf:
  train_resamples: 10
  val_ratio: 0.15
