trainer:
  ckpt_track_metric: loss
  metrics_on_train: True
  ema_metrics_on_train: False
  total_iters: 10_000_000 # may be it is too much...
  use_trainval: False
  ema:
    beta: 0.999
    update_after_step: 1000
    update_every: 10

evaluator:
  devices: ["cuda:0", "cuda:0", "cuda:0"]

data_conf:
  train_resamples: 50
  batch_size: 1024
  train_random_end: time
  train_transforms:
    '1':
      TimeToDiff:
        disable: true # Base processing must be minimal
    "3":
      CutTargetSequence:
        target_len: ${data_conf.generation_len}

# MODEL
model:
  name: LatentDiffusionGenerator
  autoencoder: 
    name: VAE
    params:
      use_time: True
    pretrain: False
    frozen: True

  latent_encoder:
    name: ConditionalDiffusionEncoder
    params:
      generation_len: ${data_conf.generation_len}
      history_len: 32 # может быть другое число, 
      base_factor: 256 # unetS: 64, unetM: 128, unetL: 256, unetXL: 512
      dim_t : 1024
      num_classes: 1
  
  params:
    history_encoder:
      name: GRU

optimizer:
  name: Adam
  params:
    lr: 1.e-3 # Note: I didn't adjust hyperparams&schedulers
    weight_decay: 1.e-9

schedulers:
  "step":
    StepLR: # Note: I didn't adjust hyperparams&schedulers
      step_size: 30

loss:
  name: DummyLoss