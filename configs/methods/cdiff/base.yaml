trainer:
  metrics_on_train: False
  total_iters: 10_000_000

evaluator:
  devices: ["cuda:0", "cuda:1"]


data_conf:
  train_resamples: 50
  batch_size: 1024
  train_random_end: time
  train_transforms:
    "3":
      CutTargetSequence:
        #target_len: ${data_conf.generation_len}
        target_len: 32
  
  
# MODEL
model:
  name: CrossDiffusionModel
  params:
    history_len: 32
    #generation_len:  ${data_conf.generation_len}
    generation_len: 32
    diffusion_steps: 200

    emb_dim_features_exp: 3
    dim_exp: 6
    heads_exp: 3
    hidden_scale_exp: 7
    encoder_layer: 6
    decoder_layer: 6
    losses: ['time_loss', 'type_loss']
    # history_encoder:
    #   checkpoint: /home/dev/2025/transaction-generation/log/generation/ready/age/gru.ckpt
    #   name: AutoregressiveGenerator
    #   latent_encoder:
    #     name: GRU
    #     params:
    #       hidden_size: 480
    #       num_layers: 1
    #       dropout: 9.594490213419128e-06
    #   autoencoder:
    #     name: BaselineAE
    #     params:
    #       cat_emb_dim: 51
    #       num_emb_dim: 18
    #       num_norm: true
    #       use_time: true
    #     pretrain: false
    #     frozen: True
    #     batch_transforms:
    #   pooler: last
    #   params: null
    # checkpoint: /trinity/home/j.chen/2.SeqDiff/test/transaction-generation-multi-features/log/generation/age/cdiff/seed_0/ckpt/epoch__0020_-_loss__-809.7.ckpt

optimizer:
  name: Adam
  params:
    lr: 0.0009858780215263926
    # lr: 0.001
    weight_decay: 0.00019210481290337137

schedulers:
  "step":
    StepLR: # Note: I didn't adjust hyperparams&schedulers
      step_size: 30


loss:
  name: DummyLoss


optuna:
  params:
    n_trials: 100
    n_startup_trials: 3
    request_list: 
    - "optimizer.params.weight_decay": 2.7220420746044506e-11
      "optimizer.params.lr": 0.0006723176382598283
      "data_conf.train_transforms.1.TimeToDiff.disable": False
      "model.params.emb_dim_features_exp": 5
      "model.params.dim_exp": 5
      "model.params.heads_exp": 1
      "model.params.hidden_scale_exp": 7
      "model.params.encoder_layer": 6 
      "model.params.decoder_layer": 8
    target_metric: ${trainer.ckpt_track_metric}
  suggestions:
    - ["optimizer.params.weight_decay", ["suggest_float", {low: 1.e-15, high: 1.e-2, log: True}]]
    - ["optimizer.params.lr", ["suggest_float", {low: 1.e-5, high: 0.1, log: True}]]

    - 
      - ["data_conf.train_transforms.1.TimeToDiff.disable", "data_conf.val_transforms.1.TimeToDiff.disable"]
      - ["suggest_categorical", {choices: [True, False]}]

    - ["model.params.emb_dim_features_exp", ["suggest_int", {low: 1, high: 8}]]
    - ["model.params.dim_exp", ["suggest_int", {low: 3, high: 10}]]
    - ["model.params.heads_exp", ["suggest_int", {low: 1, high: 3}]]

    - ["model.params.hidden_scale_exp", ["suggest_int", {low: 1, high: 10, step: 1}]]
    - ["model.params.encoder_layer", ["suggest_int", {low: 2, high: 16, step: 2}]]
    - ["model.params.decoder_layer", ["suggest_int", {low: 2, high: 16, step: 2}]]
