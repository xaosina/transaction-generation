model:
  name: AutoregressiveGenerator
  autoencoder:
    name: BaselineAE
    params:
      cat_emb_dim: 16
      num_emb_dim: 64
      num_norm: True
      use_time: True
    pretrain: False
    frozen: False
    checkpoint:
  latent_encoder:
    name: Transformer
    params:
      max_len: ${data_conf.max_seq_len}
      num_layers: 2
      scale_hidden: 4
      dropout: 0.1
      pos_dropout: 0.1 
      pos_enc_type: "cat"
      num_heads: 8

optimizer:
  name: Adam
  params:
    lr: 1.5e-3
    weight_decay: 1.e-9

schedulers:
  "step":
    StepLR:
      step_size: 30
  # "beta":
  #   BetaScheduler:
  #     init_beta: 0.01
  #     factor: 0.7
  #     patience: 4
  #     min_beta: 0.00001
  #     verbose: True

loss:
  name: baseline
  params:
    mse_weight: 0.5

optuna:
  params:
    n_trials: 100
    n_startup_trials: 10
    request_list: []
    target_metric: ${trainer.ckpt_track_metric}
  suggestions:
    - ["optimizer.params.weight_decay", ["suggest_float", {low: 1.e-15, high: 1.e-3, log: True}]]
    - ["optimizer.params.lr", ["suggest_float", {low: 1.e-5, high: 0.1, log: True}]]

    - ["model.latent_encoder.params.num_layers", [suggest_int, {low: 1, high: 10, log: False}]]
    - ["model.latent_encoder.params.scale_hidden", [suggest_int, {low: 1, high: 16, log: False}]]
    - ["model.latent_encoder.params.dropout", [suggest_float, {low: 0, high: 0.6, log: False}]]
    - ["model.latent_encoder.params.pos_dropout", [suggest_float, {low: 0, high: 0.6, log: False}]]
    - ["model.latent_encoder.params.pos_enc_type", [suggest_categorical, {choices: ["base", "cat", "learned", "none"]}]]
    - ["model.latent_encoder.params.num_heads", [suggest_categorical, {choices: [1, 2, 4, 8]}]]

    # - ["model.autoencoder.params.use_time", ["suggest_categorical", {choices: [True, False]}]]
    - 
      - ["data_conf.train_transforms.1.TimeToDiff.disable", "data_conf.val_transforms.1.TimeToDiff.disable"]
      - ["suggest_categorical", {choices: [True, False]}]
    - ["model.preprocessor.params.num_norm", ["suggest_categorical", {choices: [True, False]}]]
    - ["model.preprocessor.params.cat_emb_dim", ["suggest_int", {low: 1, high: 128, log: False}]]
    - ["model.preprocessor.params.num_emb_dim", ["suggest_int", {low: 1, high: 128, log: False}]]

    # - ["loss.params.mse_weight", ["suggest_float", {low: 0, high: 1, log: False}]]
