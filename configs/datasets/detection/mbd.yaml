patience: 10
n_classes: 2
main_metric: MulticlassAccuracy
main_loss: 
  name: nn.CrossEntropyLoss

trainer:
  ckpt_track_metric: ${main_metric}
  metrics_on_train: true
  patience: ${patience}
  total_iters: 10_000 # About 25 epoch

cc:
  src_type32: 87
  src_type11: 45
  event_subtype: 60
  dst_type11: 55
  event_type: 54
  currency: 2 # Initially 12
  dst_type12: 253
  src_type22: 84
  src_type12: 184
  # src_type31: 1455
  # src_type21: 8000
nn:
  - amount

data:
  dataset:
    parquet_path: 
    random_split: true
    split_seed: 42

    split_sizes: 
      - 0.7   # train
      - 0.15  # train_val
      - 0.15  # test

  preprocessing:
    common_pipeline: &common_pipeline
      max_seq_len: 1000
      time_name: days_since_first_tx
      index_name: client_id
      target_name: generated
      cat_cardinalities: ${cc}
      num_names: ${nn}
      batch_transforms:
        - RescaleTime:
            loc: 0.0
            scale: 365.0
        - TimeToFeatures:
            process_type: ${model.preprocess.params.time_process}
        - TargetToLong
        - MaskValid
        - Logarithm:
            names: ["amount"]

  loaders:
    train:
      split_idx: 0
      preprocessing: common_pipeline
      batch_size: 128
      drop_incomplete: true
      shuffle: true
      loop: false
      num_workers: 4
      random_seed: 42
    full_train:
      split_idx: 0
      preprocessing: common_pipeline
      batch_size: 128
      num_workers: 4
    train_val:
      split_idx: 1
      preprocessing: common_pipeline
      batch_size: 128
      num_workers: 4
    hpo_val:
      split_idx: 2
      preprocessing: common_pipeline
      batch_size: 128
      num_workers: 4

test_data:
  dataset:
    parquet_path: ${data.dataset.parquet_path}
    split_sizes: 
      - 0.0
  preprocessing:
    common_pipeline: *common_pipeline
  loaders:
    test:
      split_idx: 0
      preprocessing: common_pipeline
      batch_size: 128
      num_workers: 4

metrics:
  - name: ${main_metric}
    params: 
      num_classes: ${n_classes}
